{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yaPqHAnNv1dM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "import json\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "import pickle\n",
    "from progress.bar import ChargingBar\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tDIZEBZkKGzR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "\n",
    "torch.manual_seed(102)\n",
    "random.seed(102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BWF96lsw2HvN"
   },
   "outputs": [],
   "source": [
    "#@title ENet model { display-mode: \"form\" }\n",
    "class InitialBlock(nn.Module):\n",
    "    \"\"\"The initial block is composed of two branches:\n",
    "    1. a main branch which performs a regular convolution with stride 2;\n",
    "    2. an extension branch which performs max-pooling.\n",
    "    Doing both operations in parallel and concatenating their results\n",
    "    allows for efficient downsampling and expansion. The main branch\n",
    "    outputs 13 feature maps while the extension branch outputs 3, for a\n",
    "    total of 16 feature maps after concatenation.\n",
    "    Keyword arguments:\n",
    "    - in_channels (int): the number of input channels.\n",
    "    - out_channels (int): the number output channels.\n",
    "    - kernel_size (int, optional): the kernel size of the filters used in\n",
    "    the convolution layer. Default: 3.\n",
    "    - padding (int, optional): zero-padding added to both sides of the\n",
    "    input. Default: 0.\n",
    "    - bias (bool, optional): Adds a learnable bias to the output if\n",
    "    ``True``. Default: False.\n",
    "    - relu (bool, optional): When ``True`` ReLU is used as the activation\n",
    "    function; otherwise, PReLU is used. Default: True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 bias=False,\n",
    "                 relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU\n",
    "        else:\n",
    "            activation = nn.PReLU\n",
    "\n",
    "        # Main branch - As stated above the number of output channels for this\n",
    "        # branch is the total minus 3, since the remaining channels come from\n",
    "        # the extension branch\n",
    "        self.main_branch = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels - 3,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            bias=bias)\n",
    "\n",
    "        # Extension branch\n",
    "        self.ext_branch = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "        # Initialize batch normalization to be used after concatenation\n",
    "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # PReLU layer to apply after concatenating the branches\n",
    "        self.out_activation = activation()\n",
    "        \n",
    "        #######################################################\n",
    "        \n",
    "        self.new_main = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, (3,3), 1, 1),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=(1,1)),\n",
    "            activation(),\n",
    "            nn.Conv2d(8, 13, (5,5), (1,1), 2),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2), padding=(1,1))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "#         main = self.main_branch(x)\n",
    "        main = self.new_main(x)\n",
    "    \n",
    "        ext = self.ext_branch(x)\n",
    "\n",
    "        # Concatenate branches\n",
    "        out = torch.cat((main, ext), 1)\n",
    "\n",
    "        # Apply batch normalization\n",
    "        out = self.batch_norm(out)\n",
    "\n",
    "        return self.out_activation(out)\n",
    "\n",
    "\n",
    "class RegularBottleneck(nn.Module):\n",
    "    \"\"\"Regular bottlenecks are the main building block of ENet.\n",
    "    Main branch:\n",
    "    1. Shortcut connection.\n",
    "    Extension branch:\n",
    "    1. 1x1 convolution which decreases the number of channels by\n",
    "    ``internal_ratio``, also called a projection;\n",
    "    2. regular, dilated or asymmetric convolution;\n",
    "    3. 1x1 convolution which increases the number of channels back to\n",
    "    ``channels``, also called an expansion;\n",
    "    4. dropout as a regularizer.\n",
    "    Keyword arguments:\n",
    "    - channels (int): the number of input and output channels.\n",
    "    - internal_ratio (int, optional): a scale factor applied to\n",
    "    ``channels`` used to compute the number of\n",
    "    channels after the projection. eg. given ``channels`` equal to 128 and\n",
    "    internal_ratio equal to 2 the number of channels after the projection\n",
    "    is 64. Default: 4.\n",
    "    - kernel_size (int, optional): the kernel size of the filters used in\n",
    "    the convolution layer described above in item 2 of the extension\n",
    "    branch. Default: 3.\n",
    "    - padding (int, optional): zero-padding added to both sides of the\n",
    "    input. Default: 0.\n",
    "    - dilation (int, optional): spacing between kernel elements for the\n",
    "    convolution described in item 2 of the extension branch. Default: 1.\n",
    "    asymmetric (bool, optional): flags if the convolution described in\n",
    "    item 2 of the extension branch is asymmetric or not. Default: False.\n",
    "    - dropout_prob (float, optional): probability of an element to be\n",
    "    zeroed. Default: 0 (no dropout).\n",
    "    - bias (bool, optional): Adds a learnable bias to the output if\n",
    "    ``True``. Default: False.\n",
    "    - relu (bool, optional): When ``True`` ReLU is used as the activation\n",
    "    function; otherwise, PReLU is used. Default: True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 channels,\n",
    "                 internal_ratio=4,\n",
    "                 kernel_size=3,\n",
    "                 padding=0,\n",
    "                 dilation=1,\n",
    "                 asymmetric=False,\n",
    "                 dropout_prob=0,\n",
    "                 bias=False,\n",
    "                 relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Check in the internal_scale parameter is within the expected range\n",
    "        # [1, channels]\n",
    "        if internal_ratio <= 1 or internal_ratio > channels:\n",
    "            raise RuntimeError(\"Value out of range. Expected value in the \"\n",
    "                               \"interval [1, {0}], got internal_scale={1}.\"\n",
    "                               .format(channels, internal_ratio))\n",
    "\n",
    "        internal_channels = channels // internal_ratio\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU\n",
    "        else:\n",
    "            activation = nn.PReLU\n",
    "\n",
    "        # Main branch - shortcut connection\n",
    "\n",
    "        # Extension branch - 1x1 convolution, followed by a regular, dilated or\n",
    "        # asymmetric convolution, followed by another 1x1 convolution, and,\n",
    "        # finally, a regularizer (spatial dropout). Number of channels is constant.\n",
    "\n",
    "        # 1x1 projection convolution\n",
    "        self.ext_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                channels,\n",
    "                internal_channels,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
    "\n",
    "        # If the convolution is asymmetric we split the main convolution in\n",
    "        # two. Eg. for a 5x5 asymmetric convolution we have two convolution:\n",
    "        # the first is 5x1 and the second is 1x5.\n",
    "        if asymmetric:\n",
    "            self.ext_conv2 = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    internal_channels,\n",
    "                    internal_channels,\n",
    "                    kernel_size=(kernel_size, 1),\n",
    "                    stride=1,\n",
    "                    padding=(padding, 0),\n",
    "                    dilation=dilation,\n",
    "                    bias=bias), nn.BatchNorm2d(internal_channels), activation(),\n",
    "                nn.Conv2d(\n",
    "                    internal_channels,\n",
    "                    internal_channels,\n",
    "                    kernel_size=(1, kernel_size),\n",
    "                    stride=1,\n",
    "                    padding=(0, padding),\n",
    "                    dilation=dilation,\n",
    "                    bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
    "        else:\n",
    "            self.ext_conv2 = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    internal_channels,\n",
    "                    internal_channels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=1,\n",
    "                    padding=padding,\n",
    "                    dilation=dilation,\n",
    "                    bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
    "\n",
    "        # 1x1 expansion convolution\n",
    "        self.ext_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                internal_channels,\n",
    "                channels,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                bias=bias), nn.BatchNorm2d(channels), activation())\n",
    "\n",
    "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
    "\n",
    "        # PReLU layer to apply after adding the branches\n",
    "        self.out_activation = activation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Main branch shortcut\n",
    "        main = x\n",
    "\n",
    "        # Extension branch\n",
    "        ext = self.ext_conv1(x)\n",
    "        ext = self.ext_conv2(ext)\n",
    "        ext = self.ext_conv3(ext)\n",
    "        ext = self.ext_regul(ext)\n",
    "\n",
    "        # Add main and extension branches\n",
    "        out = main + ext\n",
    "\n",
    "        return self.out_activation(out)\n",
    "\n",
    "\n",
    "class DownsamplingBottleneck(nn.Module):\n",
    "    \"\"\"Downsampling bottlenecks further downsample the feature map size.\n",
    "    Main branch:\n",
    "    1. max pooling with stride 2; indices are saved to be used for\n",
    "    unpooling later.\n",
    "    Extension branch:\n",
    "    1. 2x2 convolution with stride 2 that decreases the number of channels\n",
    "    by ``internal_ratio``, also called a projection;\n",
    "    2. regular convolution (by default, 3x3);\n",
    "    3. 1x1 convolution which increases the number of channels to\n",
    "    ``out_channels``, also called an expansion;\n",
    "    4. dropout as a regularizer.\n",
    "    Keyword arguments:\n",
    "    - in_channels (int): the number of input channels.\n",
    "    - out_channels (int): the number of output channels.\n",
    "    - internal_ratio (int, optional): a scale factor applied to ``channels``\n",
    "    used to compute the number of channels after the projection. eg. given\n",
    "    ``channels`` equal to 128 and internal_ratio equal to 2 the number of\n",
    "    channels after the projection is 64. Default: 4.\n",
    "    - return_indices (bool, optional):  if ``True``, will return the max\n",
    "    indices along with the outputs. Useful when unpooling later.\n",
    "    - dropout_prob (float, optional): probability of an element to be\n",
    "    zeroed. Default: 0 (no dropout).\n",
    "    - bias (bool, optional): Adds a learnable bias to the output if\n",
    "    ``True``. Default: False.\n",
    "    - relu (bool, optional): When ``True`` ReLU is used as the activation\n",
    "    function; otherwise, PReLU is used. Default: True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 internal_ratio=4,\n",
    "                 return_indices=False,\n",
    "                 dropout_prob=0,\n",
    "                 bias=False,\n",
    "                 relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Store parameters that are needed later\n",
    "        self.return_indices = return_indices\n",
    "\n",
    "        # Check in the internal_scale parameter is within the expected range\n",
    "        # [1, channels]\n",
    "        if internal_ratio <= 1 or internal_ratio > in_channels:\n",
    "            raise RuntimeError(\"Value out of range. Expected value in the \"\n",
    "                               \"interval [1, {0}], got internal_scale={1}. \"\n",
    "                               .format(in_channels, internal_ratio))\n",
    "\n",
    "        internal_channels = in_channels // internal_ratio\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU\n",
    "        else:\n",
    "            activation = nn.PReLU\n",
    "\n",
    "        # Main branch - max pooling followed by feature map (channels) padding\n",
    "        self.main_max1 = nn.MaxPool2d(\n",
    "            2,\n",
    "            stride=2,\n",
    "            return_indices=return_indices)\n",
    "\n",
    "        # Extension branch - 2x2 convolution, followed by a regular, dilated or\n",
    "        # asymmetric convolution, followed by another 1x1 convolution. Number\n",
    "        # of channels is doubled.\n",
    "\n",
    "        # 2x2 projection convolution with stride 2\n",
    "        self.ext_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                internal_channels,\n",
    "                kernel_size=2,\n",
    "                stride=2,\n",
    "                bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
    "\n",
    "        # Convolution\n",
    "        self.ext_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                internal_channels,\n",
    "                internal_channels,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "                bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
    "\n",
    "        # 1x1 expansion convolution\n",
    "        self.ext_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                internal_channels,\n",
    "                out_channels,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                bias=bias), nn.BatchNorm2d(out_channels), activation())\n",
    "\n",
    "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
    "\n",
    "        # PReLU layer to apply after concatenating the branches\n",
    "        self.out_activation = activation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Main branch shortcut\n",
    "        if self.return_indices:\n",
    "            main, max_indices = self.main_max1(x)\n",
    "        else:\n",
    "            main = self.main_max1(x)\n",
    "\n",
    "        # Extension branch\n",
    "        ext = self.ext_conv1(x)\n",
    "        ext = self.ext_conv2(ext)\n",
    "        ext = self.ext_conv3(ext)\n",
    "        ext = self.ext_regul(ext)\n",
    "\n",
    "        # Main branch channel padding\n",
    "        n, ch_ext, h, w = ext.size()\n",
    "        ch_main = main.size()[1]\n",
    "        padding = torch.zeros(n, ch_ext - ch_main, h, w)\n",
    "\n",
    "        # Before concatenating, check if main is on the CPU or GPU and\n",
    "        # convert padding accordingly\n",
    "        if main.is_cuda:\n",
    "            padding = padding.cuda()\n",
    "\n",
    "        # Concatenate\n",
    "        main = torch.cat((main, padding), 1)\n",
    "\n",
    "        # Add main and extension branches\n",
    "        out = main + ext\n",
    "\n",
    "        return self.out_activation(out), max_indices\n",
    "\n",
    "\n",
    "class UpsamplingBottleneck(nn.Module):\n",
    "    \"\"\"The upsampling bottlenecks upsample the feature map resolution using max\n",
    "    pooling indices stored from the corresponding downsampling bottleneck.\n",
    "    Main branch:\n",
    "    1. 1x1 convolution with stride 1 that decreases the number of channels by\n",
    "    ``internal_ratio``, also called a projection;\n",
    "    2. max unpool layer using the max pool indices from the corresponding\n",
    "    downsampling max pool layer.\n",
    "    Extension branch:\n",
    "    1. 1x1 convolution with stride 1 that decreases the number of channels by\n",
    "    ``internal_ratio``, also called a projection;\n",
    "    2. transposed convolution (by default, 3x3);\n",
    "    3. 1x1 convolution which increases the number of channels to\n",
    "    ``out_channels``, also called an expansion;\n",
    "    4. dropout as a regularizer.\n",
    "    Keyword arguments:\n",
    "    - in_channels (int): the number of input channels.\n",
    "    - out_channels (int): the number of output channels.\n",
    "    - internal_ratio (int, optional): a scale factor applied to ``in_channels``\n",
    "     used to compute the number of channels after the projection. eg. given\n",
    "     ``in_channels`` equal to 128 and ``internal_ratio`` equal to 2 the number\n",
    "     of channels after the projection is 64. Default: 4.\n",
    "    - dropout_prob (float, optional): probability of an element to be zeroed.\n",
    "    Default: 0 (no dropout).\n",
    "    - bias (bool, optional): Adds a learnable bias to the output if ``True``.\n",
    "    Default: False.\n",
    "    - relu (bool, optional): When ``True`` ReLU is used as the activation\n",
    "    function; otherwise, PReLU is used. Default: True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 internal_ratio=4,\n",
    "                 dropout_prob=0,\n",
    "                 bias=False,\n",
    "                 relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Check in the internal_scale parameter is within the expected range\n",
    "        # [1, channels]\n",
    "        if internal_ratio <= 1 or internal_ratio > in_channels:\n",
    "            raise RuntimeError(\"Value out of range. Expected value in the \"\n",
    "                               \"interval [1, {0}], got internal_scale={1}. \"\n",
    "                               .format(in_channels, internal_ratio))\n",
    "\n",
    "        internal_channels = in_channels // internal_ratio\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU\n",
    "        else:\n",
    "            activation = nn.PReLU\n",
    "\n",
    "        # Main branch - max pooling followed by feature map (channels) padding\n",
    "        self.main_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm2d(out_channels))\n",
    "\n",
    "        # Remember that the stride is the same as the kernel_size, just like\n",
    "        # the max pooling layers\n",
    "        self.main_unpool1 = nn.MaxUnpool2d(kernel_size=2)\n",
    "\n",
    "        # Extension branch - 1x1 convolution, followed by a regular, dilated or\n",
    "        # asymmetric convolution, followed by another 1x1 convolution. Number\n",
    "        # of channels is doubled.\n",
    "\n",
    "        # 1x1 projection convolution with stride 1\n",
    "        self.ext_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels, internal_channels, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm2d(internal_channels), activation())\n",
    "\n",
    "        # Transposed convolution\n",
    "        self.ext_tconv1 = nn.ConvTranspose2d(\n",
    "            internal_channels,\n",
    "            internal_channels,\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "            bias=bias)\n",
    "        self.ext_tconv1_bnorm = nn.BatchNorm2d(internal_channels)\n",
    "        self.ext_tconv1_activation = activation()\n",
    "\n",
    "        # 1x1 expansion convolution\n",
    "        self.ext_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                internal_channels, out_channels, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm2d(out_channels), activation())\n",
    "\n",
    "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
    "\n",
    "        # PReLU layer to apply after concatenating the branches\n",
    "        self.out_activation = activation()\n",
    "\n",
    "    def forward(self, x, max_indices, output_size):\n",
    "        # Main branch shortcut\n",
    "        main = self.main_conv1(x)\n",
    "        main = self.main_unpool1(\n",
    "            main, max_indices, output_size=output_size)\n",
    "\n",
    "        # Extension branch\n",
    "        ext = self.ext_conv1(x)\n",
    "        ext = self.ext_tconv1(ext, output_size=output_size)\n",
    "        ext = self.ext_tconv1_bnorm(ext)\n",
    "        ext = self.ext_tconv1_activation(ext)\n",
    "        ext = self.ext_conv2(ext)\n",
    "        ext = self.ext_regul(ext)\n",
    "\n",
    "        # Add main and extension branches\n",
    "        out = main + ext\n",
    "\n",
    "        return self.out_activation(out)\n",
    "\n",
    "\n",
    "class ENet(nn.Module):\n",
    "    \"\"\"Generate the ENet model.\n",
    "    Keyword arguments:\n",
    "    - num_classes (int): the number of classes to segment.\n",
    "    - encoder_relu (bool, optional): When ``True`` ReLU is used as the\n",
    "    activation function in the encoder blocks/layers; otherwise, PReLU\n",
    "    is used. Default: False.\n",
    "    - decoder_relu (bool, optional): When ``True`` ReLU is used as the\n",
    "    activation function in the decoder blocks/layers; otherwise, PReLU\n",
    "    is used. Default: True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes, encoder_relu=False, decoder_relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.initial_block = InitialBlock(3, 16, relu=encoder_relu)\n",
    "\n",
    "        # Stage 1 - Encoder\n",
    "        self.downsample1_0 = DownsamplingBottleneck(\n",
    "            16,\n",
    "            64,\n",
    "            return_indices=True,\n",
    "            dropout_prob=0.01,\n",
    "            relu=encoder_relu)\n",
    "        self.regular1_1 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "        self.regular1_2 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "        self.regular1_3 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "        self.regular1_4 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "\n",
    "        # Stage 2 - Encoder\n",
    "        self.downsample2_0 = DownsamplingBottleneck(\n",
    "            64,\n",
    "            128,\n",
    "            return_indices=True,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.regular2_1 = RegularBottleneck(\n",
    "            128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated2_2 = RegularBottleneck(\n",
    "            128, dilation=2, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric2_3 = RegularBottleneck(\n",
    "            128,\n",
    "            kernel_size=5,\n",
    "            padding=2,\n",
    "            asymmetric=True,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.dilated2_4 = RegularBottleneck(\n",
    "            128, dilation=4, padding=4, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.regular2_5 = RegularBottleneck(\n",
    "            128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated2_6 = RegularBottleneck(\n",
    "            128, dilation=8, padding=8, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric2_7 = RegularBottleneck(\n",
    "            128,\n",
    "            kernel_size=5,\n",
    "            asymmetric=True,\n",
    "            padding=2,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.dilated2_8 = RegularBottleneck(\n",
    "            128, dilation=16, padding=16, dropout_prob=0.1, relu=encoder_relu)\n",
    "\n",
    "        # Stage 3 - Encoder\n",
    "        self.regular3_0 = RegularBottleneck(\n",
    "            128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated3_1 = RegularBottleneck(\n",
    "            128, dilation=2, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric3_2 = RegularBottleneck(\n",
    "            128,\n",
    "            kernel_size=5,\n",
    "            padding=2,\n",
    "            asymmetric=True,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.dilated3_3 = RegularBottleneck(\n",
    "            128, dilation=4, padding=4, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.regular3_4 = RegularBottleneck(\n",
    "            128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated3_5 = RegularBottleneck(\n",
    "            128, dilation=8, padding=8, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric3_6 = RegularBottleneck(\n",
    "            128,\n",
    "            kernel_size=5,\n",
    "            asymmetric=True,\n",
    "            padding=2,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.dilated3_7 = RegularBottleneck(\n",
    "            128, dilation=16, padding=16, dropout_prob=0.1, relu=encoder_relu)\n",
    "\n",
    "        # Stage 4 - Decoder\n",
    "        self.upsample4_0 = UpsamplingBottleneck(\n",
    "            128, 64, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.regular4_1 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.regular4_2 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "\n",
    "        # Stage 5 - Decoder\n",
    "        self.upsample5_0 = UpsamplingBottleneck(\n",
    "            64, 16, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.regular5_1 = RegularBottleneck(\n",
    "            16, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.transposed_conv = nn.ConvTranspose2d(\n",
    "            16,\n",
    "            num_classes,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial block\n",
    "        input_size = x.size()\n",
    "        x = self.initial_block(x)\n",
    "\n",
    "        # Stage 1 - Encoder\n",
    "        stage1_input_size = x.size()\n",
    "        x, max_indices1_0 = self.downsample1_0(x)\n",
    "        x = self.regular1_1(x)\n",
    "        x = self.regular1_2(x)\n",
    "        x = self.regular1_3(x)\n",
    "        x = self.regular1_4(x)\n",
    "\n",
    "        # Stage 2 - Encoder\n",
    "        stage2_input_size = x.size()\n",
    "        x, max_indices2_0 = self.downsample2_0(x)\n",
    "        x = self.regular2_1(x)\n",
    "        x = self.dilated2_2(x)\n",
    "        x = self.asymmetric2_3(x)\n",
    "        x = self.dilated2_4(x)\n",
    "        x = self.regular2_5(x)\n",
    "        x = self.dilated2_6(x)\n",
    "        x = self.asymmetric2_7(x)\n",
    "        x = self.dilated2_8(x)\n",
    "\n",
    "        # Stage 3 - Encoder\n",
    "        x = self.regular3_0(x)\n",
    "        x = self.dilated3_1(x)\n",
    "        x = self.asymmetric3_2(x)\n",
    "        x = self.dilated3_3(x)\n",
    "        x = self.regular3_4(x)\n",
    "        x = self.dilated3_5(x)\n",
    "        x = self.asymmetric3_6(x)\n",
    "        x = self.dilated3_7(x)\n",
    "\n",
    "        # Stage 4 - Decoder\n",
    "        x = self.upsample4_0(x, max_indices2_0, output_size=stage2_input_size)\n",
    "        x = self.regular4_1(x)\n",
    "        x = self.regular4_2(x)\n",
    "\n",
    "        # Stage 5 - Decoder\n",
    "        x = self.upsample5_0(x, max_indices1_0, output_size=stage1_input_size)\n",
    "        x = self.regular5_1(x)\n",
    "        x = self.transposed_conv(x, output_size=input_size)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "omCkbvwq8T2o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENet(\n",
       "  (initial_block): InitialBlock(\n",
       "    (main_branch): Conv2d(3, 13, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (ext_branch): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "    (new_main): Sequential(\n",
       "      (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "      (3): Conv2d(8, 13, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (downsample1_0): DownsamplingBottleneck(\n",
       "    (main_max1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(16, 4, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.01)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (regular1_1): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.01)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (regular1_2): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.01)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (regular1_3): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.01)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (regular1_4): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.01)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (downsample2_0): DownsamplingBottleneck(\n",
       "    (main_max1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(64, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.1)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (regular2_1): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.1)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (dilated2_2): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.1)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (asymmetric2_3): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.1)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (dilated2_4): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.1)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (regular2_5): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.1)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (dilated2_6): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.1)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (asymmetric2_7): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.1)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (dilated2_8): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.1)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (regular3_0): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.1)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (dilated3_1): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.1)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (asymmetric3_2): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.1)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (dilated3_3): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.1)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (regular3_4): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.1)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (dilated3_5): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.1)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (asymmetric3_6): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.1)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (dilated3_7): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.1)\n",
       "    (out_activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (upsample4_0): UpsamplingBottleneck(\n",
       "    (main_conv1): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (main_unpool1): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (ext_tconv1): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (ext_tconv1_bnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ext_tconv1_activation): ReLU()\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.1)\n",
       "    (out_activation): ReLU()\n",
       "  )\n",
       "  (regular4_1): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.1)\n",
       "    (out_activation): ReLU()\n",
       "  )\n",
       "  (regular4_2): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.1)\n",
       "    (out_activation): ReLU()\n",
       "  )\n",
       "  (upsample5_0): UpsamplingBottleneck(\n",
       "    (main_conv1): Sequential(\n",
       "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (main_unpool1): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (ext_tconv1): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (ext_tconv1_bnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ext_tconv1_activation): ReLU()\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.1)\n",
       "    (out_activation): ReLU()\n",
       "  )\n",
       "  (regular5_1): RegularBottleneck(\n",
       "    (ext_conv1): Sequential(\n",
       "      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (ext_conv2): Sequential(\n",
       "      (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (ext_conv3): Sequential(\n",
       "      (0): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (ext_regul): Dropout2d(p=0.1)\n",
       "    (out_activation): ReLU()\n",
       "  )\n",
       "  (transposed_conv): ConvTranspose2d(16, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ENet(num_classes=40).to(device)\n",
    "model.load_state_dict(torch.load('/home/tejus/road-segmentation/runs/exp-2_5epochs_lr_0.001_batch_size_8_weights_road_pavement_5_fullhd/best_val_recent.wts'))\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "8w1cK2Qm2_cf"
   },
   "outputs": [],
   "source": [
    "#@title color2id id2name dictionary for encodings\n",
    " \n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "Label = namedtuple( 'Label' , [\n",
    "\n",
    "    'name'        , \n",
    "    'id'          ,\n",
    "\n",
    "    'csId'        ,\n",
    "\n",
    "    'csTrainId'   ,    \n",
    "\n",
    "    'level4Id'    , \n",
    "    'level3Id'    , \n",
    "    'level2IdName', \n",
    "    'level2Id'    , \n",
    "    'level1Id'    , \n",
    "\n",
    "    'hasInstances', \n",
    "    'ignoreInEval', \n",
    "    'color'       , \n",
    "    ] )\n",
    "labels = [\n",
    "    #       name                     id    csId     csTrainId level4id        level3Id  category           level2Id      level1Id  hasInstances   ignoreInEval   color\n",
    "    Label(  'road'                 ,  0   ,  7 ,     0 ,       0   ,     0  ,   'drivable'            , 0           , 0      , False        , False        , (128, 64,128)  ),\n",
    "    Label(  'parking'              ,  1   ,  9 ,   255 ,       1   ,     1  ,   'drivable'            , 1           , 0      , False        , False         , (250,170,160)  ),\n",
    "    Label(  'drivable fallback'    ,  2   ,  255 ,   255 ,     2   ,       1  ,   'drivable'            , 1           , 0      , False        , False         , ( 81,  0, 81)  ),\n",
    "    Label(  'sidewalk'             ,  3   ,  8 ,     1 ,       3   ,     2  ,   'non-drivable'        , 2           , 1      , False        , False        , (244, 35,232)  ),\n",
    "    Label(  'rail track'           ,  4   , 10 ,   255 ,       3   ,     3  ,   'non-drivable'        , 3           , 1      , False        , False         , (230,150,140)  ),\n",
    "    Label(  'non-drivable fallback',  5   , 255 ,     9 ,      4   ,      3  ,   'non-drivable'        , 3           , 1      , False        , False        , (152,251,152)  ),\n",
    "    Label(  'person'               ,  6   , 24 ,    11 ,       5   ,     4  ,   'living-thing'        , 4           , 2      , True         , False        , (220, 20, 60)  ),\n",
    "    Label(  'animal'               ,  7   , 255 ,   255 ,      6   ,      4  ,   'living-thing'        , 4           , 2      , True         , True        , (246, 198, 145)),\n",
    "    Label(  'rider'                ,  8   , 25 ,    12 ,       7   ,     5  ,   'living-thing'        , 5           , 2      , True         , False        , (255,  0,  0)  ),\n",
    "    Label(  'motorcycle'           ,  9   , 32 ,    17 ,       8   ,     6  ,   '2-wheeler'           , 6           , 3      , True         , False        , (  0,  0,230)  ),\n",
    "    Label(  'bicycle'              , 10   , 33 ,    18 ,       9   ,     7  ,   '2-wheeler'           , 6           , 3      , True         , False        , (119, 11, 32)  ),\n",
    "    Label(  'autorickshaw'         , 11   , 255 ,   255 ,     10   ,      8  ,   'autorickshaw'        , 7           , 3      , True         , False        , (255, 204, 54) ),\n",
    "    Label(  'car'                  , 12   , 26 ,    13 ,      11   ,     9  ,   'car'                 , 7           , 3      , True         , False        , (  0,  0,142)  ),\n",
    "    Label(  'truck'                , 13   , 27 ,    14 ,      12   ,     10 ,   'large-vehicle'       , 8           , 3      , True         , False        , (  0,  0, 70)  ),\n",
    "    Label(  'bus'                  , 14   , 28 ,    15 ,      13   ,     11 ,   'large-vehicle'       , 8           , 3      , True         , False        , (  0, 60,100)  ),\n",
    "    Label(  'caravan'              , 15   , 29 ,   255 ,      14   ,     12 ,   'large-vehicle'       , 8           , 3      , True         , True         , (  0,  0, 90)  ),\n",
    "    Label(  'trailer'              , 16   , 30 ,   255 ,      15   ,     12 ,   'large-vehicle'       , 8           , 3      , True         , True         , (  0,  0,110)  ),\n",
    "    Label(  'train'                , 17   , 31 ,    16 ,      15   ,     12 ,   'large-vehicle'       , 8           , 3      , True         , True        , (  0, 80,100)  ),\n",
    "    Label(  'vehicle fallback'     , 18   , 355 ,   255 ,     15   ,      12 ,   'large-vehicle'       , 8           , 3      , True         , False        , (136, 143, 153)),  \n",
    "    Label(  'curb'                 , 19   ,255 ,   255 ,      16   ,     13 ,   'barrier'             , 9           , 4      , False        , False        , (220, 190, 40)),\n",
    "    Label(  'wall'                 , 20   , 12 ,     3 ,      17   ,     14 ,   'barrier'             , 9           , 4      , False        , False        , (102,102,156)  ),\n",
    "    Label(  'fence'                , 21   , 13 ,     4 ,      18   ,     15 ,   'barrier'             , 10           , 4      , False        , False        , (190,153,153)  ),\n",
    "    Label(  'guard rail'           , 22   , 14 ,   255 ,      19   ,     16 ,   'barrier'             , 10          , 4      , False        , False         , (180,165,180)  ),\n",
    "    Label(  'billboard'            , 23   , 255 ,   255 ,     20   ,      17 ,   'structures'          , 11           , 4      , False        , False        , (174, 64, 67) ),\n",
    "    Label(  'traffic sign'         , 24   , 20 ,     7 ,      21   ,     18 ,   'structures'          , 11          , 4      , False        , False        , (220,220,  0)  ),\n",
    "    Label(  'traffic light'        , 25   , 19 ,     6 ,      22   ,     19 ,   'structures'          , 11          , 4      , False        , False        , (250,170, 30)  ),\n",
    "    Label(  'pole'                 , 26   , 17 ,     5 ,      23   ,     20 ,   'structures'          , 12          , 4      , False        , False        , (153,153,153)  ),\n",
    "    Label(  'polegroup'            , 27   , 18 ,   255 ,      23   ,     20 ,   'structures'          , 12          , 4      , False        , False         , (153,153,153)  ),\n",
    "    Label(  'obs-str-bar-fallback' , 28   , 255 ,   255 ,     24   ,      21 ,   'structures'          , 12          , 4      , False        , False        , (169, 187, 214) ),  \n",
    "    Label(  'building'             , 29   , 11 ,     2 ,      25   ,     22 ,   'construction'        , 13          , 5      , False        , False        , ( 70, 70, 70)  ),\n",
    "    Label(  'bridge'               , 30   , 15 ,   255 ,      26   ,     23 ,   'construction'        , 13          , 5      , False        , False         , (150,100,100)  ),\n",
    "    Label(  'tunnel'               , 31   , 16 ,   255 ,      26   ,     23 ,   'construction'        , 13          , 5      , False        , False         , (150,120, 90)  ),\n",
    "    Label(  'vegetation'           , 32   , 21 ,     8 ,      27   ,     24 ,   'vegetation'          , 14          , 5      , False        , False        , (107,142, 35)  ),\n",
    "    Label(  'sky'                  , 33   , 23 ,    10 ,      28   ,     25 ,   'sky'                 , 15          , 6      , False        , False        , ( 70,130,180)  ),\n",
    "    Label(  'fallback background'  , 34   , 255 ,   255 ,     29   ,      25 ,   'object fallback'     , 15          , 6      , False        , False        , (169, 187, 214)),\n",
    "    Label(  'unlabeled'            , 35   ,  0  ,     255 ,   255   ,      255 ,   'void'                , 255         , 255    , False        , True         , (  0,  0,  0)  ),\n",
    "    Label(  'ego vehicle'          , 36   ,  1  ,     255 ,   255   ,      255 ,   'void'                , 255         , 255    , False        , True         , (  0,  0,  0)  ),\n",
    "    Label(  'rectification border' , 37   ,  2  ,     255 ,   255   ,      255 ,   'void'                , 255         , 255    , False        , True         , (  0,  0,  0)  ),\n",
    "    Label(  'out of roi'           , 38   ,  3  ,     255 ,   255   ,      255 ,   'void'                , 255         , 255    , False        , True         , (  0,  0,  0)  ),\n",
    "    Label(  'license plate'        , 39   , 255 ,     255 ,   255   ,      255 ,   'vehicle'             , 255         , 255    , False        , True         , (  0,  0,142)  ),\n",
    "    \n",
    "]           \n",
    "\n",
    "\n",
    "\n",
    "#colour to id dictionary input: pixel values output:id \n",
    "color2id = { label.color    : label.id for label in labels }\n",
    "\n",
    "#id to name dictionary input: pixel values output:label \n",
    "id2name = { label.id    : label.name for label in labels }\n",
    "\n",
    "id2color = { label.id    : label.color for label in labels }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "K_azWCO635gM"
   },
   "outputs": [],
   "source": [
    "#@title Json to label helpers\n",
    "import os\n",
    "import json\n",
    "from collections import namedtuple\n",
    "  \n",
    "# get current date and time\n",
    "import datetime\n",
    "import locale\n",
    "\n",
    "# A point in a polygon\n",
    "Point = namedtuple('Point', ['x', 'y'])\n",
    "# Class that contains the information of a single annotated object\n",
    "class CsObject:\n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "        # the label\n",
    "        self.label    = \"\"\n",
    "        # the polygon as list of points\n",
    "        self.polygon  = []\n",
    "\n",
    "        # the object ID\n",
    "        self.id       = -1\n",
    "        # If deleted or not\n",
    "        self.deleted  = 0\n",
    "        # If verified or not\n",
    "        self.verified = 0\n",
    "        # The date string\n",
    "        self.date     = \"\"\n",
    "        # The username\n",
    "        self.user     = \"\"\n",
    "        # Draw the object\n",
    "        # Not read from or written to JSON\n",
    "        # Set to False if deleted object\n",
    "        # Might be set to False by the application for other reasons\n",
    "        self.draw     = True\n",
    "\n",
    "    def __str__(self):\n",
    "        polyText = \"\"\n",
    "        if self.polygon:\n",
    "            if len(self.polygon) <= 4:\n",
    "                for p in self.polygon:\n",
    "                    polyText += '({},{}) '.format( p.x , p.y )\n",
    "            else:\n",
    "                polyText += '({},{}) ({},{}) ... ({},{}) ({},{})'.format(\n",
    "                    self.polygon[ 0].x , self.polygon[ 0].y ,\n",
    "                    self.polygon[ 1].x , self.polygon[ 1].y ,\n",
    "                    self.polygon[-2].x , self.polygon[-2].y ,\n",
    "                    self.polygon[-1].x , self.polygon[-1].y )\n",
    "        else:\n",
    "            polyText = \"none\"\n",
    "        text = \"Object: {} - {}\".format( self.label , polyText )\n",
    "        return text\n",
    "\n",
    "    def fromJsonText(self, jsonText, objId):\n",
    "        self.id = objId\n",
    "        self.label = str(jsonText['label'])\n",
    "        self.polygon = [ Point(p[0],p[1]) for p in jsonText['polygon'] ]\n",
    "        if 'deleted' in jsonText.keys():\n",
    "            self.deleted = jsonText['deleted']\n",
    "        else:\n",
    "            self.deleted = 0\n",
    "        if 'verified' in jsonText.keys():\n",
    "            self.verified = jsonText['verified']\n",
    "        else:\n",
    "            self.verified = 1\n",
    "        if 'user' in jsonText.keys():\n",
    "            self.user = jsonText['user']\n",
    "        else:\n",
    "            self.user = ''\n",
    "        if 'date' in jsonText.keys():\n",
    "            self.date = jsonText['date']\n",
    "        else:\n",
    "            self.date = ''\n",
    "        if self.deleted == 1:\n",
    "            self.draw = False\n",
    "        else:\n",
    "            self.draw = True\n",
    "\n",
    "    def toJsonText(self):\n",
    "        objDict = {}\n",
    "        objDict['label'] = self.label\n",
    "        objDict['id'] = self.id\n",
    "        objDict['deleted'] = self.deleted\n",
    "        objDict['verified'] = self.verified\n",
    "        objDict['user'] = self.user\n",
    "        objDict['date'] = self.date\n",
    "        objDict['polygon'] = []\n",
    "        for pt in self.polygon:\n",
    "            objDict['polygon'].append([pt.x, pt.y])\n",
    "\n",
    "        return objDict\n",
    "\n",
    "    def updateDate( self ):\n",
    "        try:\n",
    "            locale.setlocale( locale.LC_ALL , 'en_US.utf8' )\n",
    "        except locale.Error:\n",
    "            locale.setlocale( locale.LC_ALL , 'us_us.utf8' )\n",
    "        except:\n",
    "            pass\n",
    "        self.date = datetime.datetime.now().strftime(\"%d-%b-%Y %H:%M:%S\")\n",
    "\n",
    "    # Mark the object as deleted\n",
    "    def delete(self):\n",
    "        self.deleted = 1\n",
    "        self.draw    = False\n",
    "\n",
    "class Annotation:\n",
    "    # Constructor\n",
    "    def __init__(self, imageWidth=0, imageHeight=0):\n",
    "        # the width of that image and thus of the label image\n",
    "        self.imgWidth  = imageWidth\n",
    "        # the height of that image and thus of the label image\n",
    "        self.imgHeight = imageHeight\n",
    "        # the list of objects\n",
    "        self.objects = []\n",
    "\n",
    "    def toJson(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=4)\n",
    "\n",
    "    def fromJsonText(self, jsonText):\n",
    "        jsonDict = json.loads(jsonText)\n",
    "        self.imgWidth  = int(jsonDict['imgWidth'])\n",
    "        self.imgHeight = int(jsonDict['imgHeight'])\n",
    "        self.objects   = []\n",
    "        for objId, objIn in enumerate(jsonDict[ 'objects' ]):\n",
    "            obj = CsObject()\n",
    "            obj.fromJsonText(objIn, objId)\n",
    "            self.objects.append(obj)\n",
    "\n",
    "    def toJsonText(self):\n",
    "        jsonDict = {}\n",
    "        jsonDict['imgWidth'] = self.imgWidth\n",
    "        jsonDict['imgHeight'] = self.imgHeight\n",
    "        jsonDict['objects'] = []\n",
    "        for obj in self.objects:\n",
    "            objDict = obj.toJsonText()\n",
    "            jsonDict['objects'].append(objDict)\n",
    "  \n",
    "        return jsonDict\n",
    "\n",
    "    # Read a json formatted polygon file and return the annotation\n",
    "    def fromJsonFile(self, jsonFile):\n",
    "        if not os.path.isfile(jsonFile):\n",
    "            print('Given json file not found: {}'.format(jsonFile))\n",
    "            return\n",
    "        with open(jsonFile, 'r') as f:\n",
    "            jsonText = f.read()\n",
    "            self.fromJsonText(jsonText)\n",
    "\n",
    "    def toJsonFile(self, jsonFile):\n",
    "        with open(jsonFile, 'w') as f:\n",
    "            f.write(self.toJson())\n",
    "#!/usr/bin/python\n",
    "#\n",
    "# AutoNUE labels\n",
    "#\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Definitions\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# a label and all meta information\n",
    "Label = namedtuple( 'Label' , [\n",
    "\n",
    "    'name'        , \n",
    "    'id'          ,\n",
    "\n",
    "    'csId'        ,\n",
    "\n",
    "    'csTrainId'   ,    \n",
    "\n",
    "    'level4Id'    , \n",
    "    'level3Id'    , \n",
    "    'level2IdName', \n",
    "    'level2Id'    , \n",
    "    'level1Id'    , \n",
    "\n",
    "    'hasInstances', \n",
    "    'ignoreInEval', \n",
    "    'color'       , \n",
    "    ] )\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# A list of all labels\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "labels = [\n",
    "    #       name                     id    csId     csTrainId level4id        level3Id  category           level2Id      level1Id  hasInstances   ignoreInEval   color\n",
    "    Label(  'road'                 ,  0   ,  7 ,     0 ,       0   ,     0  ,   'drivable'            , 0           , 0      , False        , False        , (128, 64,128)  ),\n",
    "    Label(  'parking'              ,  1   ,  9 ,   255 ,       1   ,     1  ,   'drivable'            , 1           , 0      , False        , False         , (250,170,160)  ),\n",
    "    Label(  'drivable fallback'    ,  2   ,  255 ,   255 ,     2   ,       1  ,   'drivable'            , 1           , 0      , False        , False         , ( 81,  0, 81)  ),\n",
    "    Label(  'sidewalk'             ,  3   ,  8 ,     1 ,       3   ,     2  ,   'non-drivable'        , 2           , 1      , False        , False        , (244, 35,232)  ),\n",
    "    Label(  'rail track'           ,  4   , 10 ,   255 ,       3   ,     3  ,   'non-drivable'        , 3           , 1      , False        , False         , (230,150,140)  ),\n",
    "    Label(  'non-drivable fallback',  5   , 255 ,     9 ,      4   ,      3  ,   'non-drivable'        , 3           , 1      , False        , False        , (152,251,152)  ),\n",
    "    Label(  'person'               ,  6   , 24 ,    11 ,       5   ,     4  ,   'living-thing'        , 4           , 2      , True         , False        , (220, 20, 60)  ),\n",
    "    Label(  'animal'               ,  7   , 255 ,   255 ,      6   ,      4  ,   'living-thing'        , 4           , 2      , True         , True        , (246, 198, 145)),\n",
    "    Label(  'rider'                ,  8   , 25 ,    12 ,       7   ,     5  ,   'living-thing'        , 5           , 2      , True         , False        , (255,  0,  0)  ),\n",
    "    Label(  'motorcycle'           ,  9   , 32 ,    17 ,       8   ,     6  ,   '2-wheeler'           , 6           , 3      , True         , False        , (  0,  0,230)  ),\n",
    "    Label(  'bicycle'              , 10   , 33 ,    18 ,       9   ,     7  ,   '2-wheeler'           , 6           , 3      , True         , False        , (119, 11, 32)  ),\n",
    "    Label(  'autorickshaw'         , 11   , 255 ,   255 ,     10   ,      8  ,   'autorickshaw'        , 7           , 3      , True         , False        , (255, 204, 54) ),\n",
    "    Label(  'car'                  , 12   , 26 ,    13 ,      11   ,     9  ,   'car'                 , 7           , 3      , True         , False        , (  0,  0,142)  ),\n",
    "    Label(  'truck'                , 13   , 27 ,    14 ,      12   ,     10 ,   'large-vehicle'       , 8           , 3      , True         , False        , (  0,  0, 70)  ),\n",
    "    Label(  'bus'                  , 14   , 28 ,    15 ,      13   ,     11 ,   'large-vehicle'       , 8           , 3      , True         , False        , (  0, 60,100)  ),\n",
    "    Label(  'caravan'              , 15   , 29 ,   255 ,      14   ,     12 ,   'large-vehicle'       , 8           , 3      , True         , True         , (  0,  0, 90)  ),\n",
    "    Label(  'trailer'              , 16   , 30 ,   255 ,      15   ,     12 ,   'large-vehicle'       , 8           , 3      , True         , True         , (  0,  0,110)  ),\n",
    "    Label(  'train'                , 17   , 31 ,    16 ,      15   ,     12 ,   'large-vehicle'       , 8           , 3      , True         , True        , (  0, 80,100)  ),\n",
    "    Label(  'vehicle fallback'     , 18   , 355 ,   255 ,     15   ,      12 ,   'large-vehicle'       , 8           , 3      , True         , False        , (136, 143, 153)),  \n",
    "    Label(  'curb'                 , 19   ,255 ,   255 ,      16   ,     13 ,   'barrier'             , 9           , 4      , False        , False        , (220, 190, 40)),\n",
    "    Label(  'wall'                 , 20   , 12 ,     3 ,      17   ,     14 ,   'barrier'             , 9           , 4      , False        , False        , (102,102,156)  ),\n",
    "    Label(  'fence'                , 21   , 13 ,     4 ,      18   ,     15 ,   'barrier'             , 10           , 4      , False        , False        , (190,153,153)  ),\n",
    "    Label(  'guard rail'           , 22   , 14 ,   255 ,      19   ,     16 ,   'barrier'             , 10          , 4      , False        , False         , (180,165,180)  ),\n",
    "    Label(  'billboard'            , 23   , 255 ,   255 ,     20   ,      17 ,   'structures'          , 11           , 4      , False        , False        , (174, 64, 67) ),\n",
    "    Label(  'traffic sign'         , 24   , 20 ,     7 ,      21   ,     18 ,   'structures'          , 11          , 4      , False        , False        , (220,220,  0)  ),\n",
    "    Label(  'traffic light'        , 25   , 19 ,     6 ,      22   ,     19 ,   'structures'          , 11          , 4      , False        , False        , (250,170, 30)  ),\n",
    "    Label(  'pole'                 , 26   , 17 ,     5 ,      23   ,     20 ,   'structures'          , 12          , 4      , False        , False        , (153,153,153)  ),\n",
    "    Label(  'polegroup'            , 27   , 18 ,   255 ,      23   ,     20 ,   'structures'          , 12          , 4      , False        , False         , (153,153,153)  ),\n",
    "    Label(  'obs-str-bar-fallback' , 28   , 255 ,   255 ,     24   ,      21 ,   'structures'          , 12          , 4      , False        , False        , (169, 187, 214) ),  \n",
    "    Label(  'building'             , 29   , 11 ,     2 ,      25   ,     22 ,   'construction'        , 13          , 5      , False        , False        , ( 70, 70, 70)  ),\n",
    "    Label(  'bridge'               , 30   , 15 ,   255 ,      26   ,     23 ,   'construction'        , 13          , 5      , False        , False         , (150,100,100)  ),\n",
    "    Label(  'tunnel'               , 31   , 16 ,   255 ,      26   ,     23 ,   'construction'        , 13          , 5      , False        , False         , (150,120, 90)  ),\n",
    "    Label(  'vegetation'           , 32   , 21 ,     8 ,      27   ,     24 ,   'vegetation'          , 14          , 5      , False        , False        , (107,142, 35)  ),\n",
    "    Label(  'sky'                  , 33   , 23 ,    10 ,      28   ,     25 ,   'sky'                 , 15          , 6      , False        , False        , ( 70,130,180)  ),\n",
    "    Label(  'fallback background'  , 34   , 255 ,   255 ,     29   ,      25 ,   'object fallback'     , 15          , 6      , False        , False        , (169, 187, 214)),\n",
    "    Label(  'unlabeled'            , 35   ,  0  ,     255 ,   255   ,      255 ,   'void'                , 255         , 255    , False        , True         , (  0,  0,  0)  ),\n",
    "    Label(  'ego vehicle'          , 36   ,  1  ,     255 ,   255   ,      255 ,   'void'                , 255         , 255    , False        , True         , (  0,  0,  0)  ),\n",
    "    Label(  'rectification border' , 37   ,  2  ,     255 ,   255   ,      255 ,   'void'                , 255         , 255    , False        , True         , (  0,  0,  0)  ),\n",
    "    Label(  'out of roi'           , 38   ,  3  ,     255 ,   255   ,      255 ,   'void'                , 255         , 255    , False        , True         , (  0,  0,  0)  ),\n",
    "    Label(  'license plate'        , 39   , 255 ,     255 ,   255   ,      255 ,   'vehicle'             , 255         , 255    , False        , True         , (  0,  0,142)  ),\n",
    "    \n",
    "]           \n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Create dictionaries for a fast lookup\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Please refer to the main method below for example usages!\n",
    "\n",
    "# name to label object\n",
    "name2label      = { label.name    : label for label in labels           }\n",
    "# id to label object\n",
    "id2label        = { label.id      : label for label in labels           }\n",
    "\n",
    "def assureSingleInstanceName( name ):\n",
    "    # if the name is known, it is not a group\n",
    "    if name in name2label:\n",
    "        return name\n",
    "    # test if the name actually denotes a group\n",
    "    if not name.endswith(\"group\"):\n",
    "        return None\n",
    "    # remove group\n",
    "    name = name[:-len(\"group\")]\n",
    "    # test if the new name exists\n",
    "    if not name in name2label:\n",
    "        return None\n",
    "    # test if the new name denotes a label that actually has instances\n",
    "    if not name2label[name].hasInstances:\n",
    "        return None\n",
    "    # all good then\n",
    "    return name\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Main for testing\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# just a dummy main\n",
    "# if __name__ == \"__main__\":\n",
    "    # # Print all the labels\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jDB09hbtut9C"
   },
   "outputs": [],
   "source": [
    "def jsonToPIL(json_file):\n",
    "  annotation = Annotation()\n",
    "  annotation.fromJsonFile(json_file)\n",
    "  size = (annotation.imgWidth, annotation.imgHeight)\n",
    "  backgroundId = name2label['unlabeled'].id\n",
    "  instanceImg = Image.new(\"I\", size, backgroundId)\n",
    "\n",
    "  # a drawer to draw into the image\n",
    "  drawer = ImageDraw.Draw(instanceImg)\n",
    "  encoding = 'id'\n",
    "  # loop over all objects\n",
    "  if True:\n",
    "      for obj in annotation.objects:\n",
    "          label = obj.label\n",
    "          # if label == 'person':\n",
    "          #     print \"person\"\n",
    "          polygon = obj.polygon\n",
    "\n",
    "          # If the object is deleted, skip it\n",
    "          if obj.deleted or len(polygon) < 2:\n",
    "              continue\n",
    "\n",
    "          # if the label is not known, but ends with a 'group' (e.g. cargroup)\n",
    "          # try to remove the s and see if that works\n",
    "          # also we know that this polygon describes a group\n",
    "          isGroup = False\n",
    "          if (not label in name2label) and label.endswith('group'):\n",
    "              label = label[:-len('group')]\n",
    "              isGroup = True\n",
    "\n",
    "\n",
    "           # the label tuple\n",
    "          labelTuple = name2label[label]\n",
    "\n",
    "          # get the class ID\n",
    "          if encoding == \"id\":\n",
    "              id = labelTuple.id\n",
    "          elif encoding == \"csId\":\n",
    "              id = labelTuple.csId\n",
    "          elif encoding == \"csTrainId\":\n",
    "              id = labelTuple.csTrainId\n",
    "          elif encoding == \"level4Id\":\n",
    "              id = labelTuple.level4Id\n",
    "          elif encoding == \"level3Id\":\n",
    "              id = labelTuple.level3Id\n",
    "          elif encoding == \"level2Id\":\n",
    "              id = labelTuple.level2Id\n",
    "          elif encoding == \"level1Id\":\n",
    "              id = labelTuple.level1Id\n",
    "\n",
    "\n",
    "\n",
    "          # If the ID is negative that polygon should not be drawn\n",
    "          if id < 0:\n",
    "              continue\n",
    "\n",
    "          # print 'id is ', id\n",
    "\n",
    "          try:\n",
    "            # if id > 24000 and id < 25000:\n",
    "                # print id\n",
    "              drawer.polygon(polygon, fill=id)\n",
    "          except:\n",
    "              print(\"Failed to draw polygon with label {} and id {}: {}\".format(\n",
    "                  label, id, polygon))\n",
    "              raise\n",
    "  return instanceImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uRO-kfizvJxq"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fWMICeEHSdm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, list_IDs, labels):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "        r = transforms.Resize(size=(720, 1280))\n",
    "        X = transform_train(r(Image.open(ID)))\n",
    "\n",
    "        instanceImg = r(jsonToPIL(self.labels[ID]))\n",
    "        y = torch.squeeze(transforms.ToTensor()(instanceImg))\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JbyRJivmNy0L"
   },
   "outputs": [],
   "source": [
    "image_list_1 = []\n",
    "image_list_2 = []#For 2 different sizes of images\n",
    "labels_dict = {}\n",
    "image_list = []\n",
    "#path = \"/content/drive/My Drive/processed\"\n",
    "path = \"/mnt/data/road-segmentation/processed_all\"\n",
    "counter_1 = 0\n",
    "counter_2 = 0\n",
    "for root, dirs, files in os.walk(path+\"/image\", topdown=False):\n",
    "    for name in files:\n",
    "\n",
    "        if os.path.exists(path+\"/label/\"+name.split(\".\")[0]+\".json\"):\n",
    "#             if Image.open(path+\"/image/\"+name).size == (1920,1080):\n",
    "#                 image_list_1.append(path+\"/image/\"+name)\n",
    "#                 counter_1 += 1\n",
    "#             else:\n",
    "#                 image_list_2.append(path+\"/image/\"+name)\n",
    "#                 counter_2 += 1\n",
    "            \n",
    "            image_list.append(path+\"/image/\"+name)\n",
    "            labels_dict[path+\"/image/\"+name] = path+\"/label/\"+name.split(\".\")[0]+\".json\"\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kau89ro8OwRF"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'batch_size': 2,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 12}\n",
    "# max_epochs = 40\n",
    "max_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Znh5Smee76V3"
   },
   "outputs": [],
   "source": [
    "#!pip install adabound\n",
    "#import adabound\n",
    "#optimizer = adabound.AdaBound(model.parameters(), lr=1e-3, final_lr=0.1)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7974"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(image_list_2)\n",
    "# len(image_list_1)\n",
    "len(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.shuffle(image_list_1)\n",
    "# random.shuffle(image_list_2)\n",
    "random.shuffle(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J17q_TOkPpJ_"
   },
   "outputs": [],
   "source": [
    "# Generators\n",
    "# training_set_1 = Dataset(image_list_1[:5000], labels_dict)\n",
    "# training_generator_1 = data.DataLoader(training_set_1, **params)\n",
    "\n",
    "# training_set_2 = Dataset(image_list_2[:2500], labels_dict)\n",
    "# training_generator_2 = data.DataLoader(training_set_2, **params)\n",
    "\n",
    "# test_set_1 = Dataset(image_list_1[5000:], labels_dict)\n",
    "# test_generator_1 = data.DataLoader(test_set_1, **params)\n",
    "\n",
    "# test_set_2 = Dataset(image_list_2[2500:], labels_dict)\n",
    "# test_generator_2 = data.DataLoader(test_set_2, **params)\n",
    "\n",
    "training_set = Dataset(image_list[:7000], labels_dict)\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "test_set = Dataset(image_list[7000:], labels_dict)\n",
    "test_generator = data.DataLoader(test_set, **params)\n",
    "\n",
    "#loss\n",
    "weight = torch.ones(size=(40,)) #All weights set to 1\n",
    "weight[0] = 5 \n",
    "weight[3] = 5 #road and pavement weights\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_set_test = Dataset(image_list_1[0:1], labels_dict)\n",
    "# training_generator_test = data.DataLoader(training_set_test, **params)\n",
    "# for local_batch, local_labels in training_generator_test:\n",
    "#     print(sys.getsizeof(local_batch))\n",
    "#     local_batch, local_labels = local_batch.to(device), local_labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(training_generator_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "#SummaryWriter encapsulates everything\n",
    "exp_name = 'exp-2_5epochs_lr_0.001_batch_size_8_weights_road_pavement_5_fullhd'\n",
    "# os.mkdir(exp_name)\n",
    "writer = SummaryWriter('runs/'+exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(image_list_1)+len(image_list_2)-7500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = math.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = ChargingBar('Processing', max=max_epochs, suffix='%(percent).2f%% - %(elapsed).2f%% - %(eta).2f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "id": "u70WtSMqP84f",
    "outputId": "ba0cd0df-b8b2-4329-9a37-57f22e6f1005"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26]training loss: 0.211\n",
      "[26]validation loss: 0.500\n",
      "[27]training loss: 0.210\n",
      "[27]validation loss: 0.505\n",
      "[28]training loss: 0.209\n",
      "[28]validation loss: 0.498\n",
      "[29]training loss: 0.210\n",
      "[29]validation loss: 0.502\n",
      "[30]training loss: 0.210\n",
      "[30]validation loss: 0.500\n",
      "[31]training loss: 0.209\n",
      "[31]validation loss: 0.502\n",
      "[32]training loss: 0.209\n",
      "[32]validation loss: 0.498\n",
      "[33]training loss: 0.209\n",
      "[33]validation loss: 0.503\n",
      "[34]training loss: 0.209\n",
      "[34]validation loss: 0.498\n",
      "[35]training loss: 0.209\n",
      "[35]validation loss: 0.503\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "for epoch in range(max_epochs):\n",
    "    # Training\n",
    "\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    for local_batch, local_labels in training_generator:\n",
    "        # Transfer to GPU\n",
    "        \n",
    "        local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(local_batch)\n",
    "        loss = criterion(outputs, local_labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "        \n",
    "#     for local_batch, local_labels in training_generator_2:\n",
    "#         # Transfer to GPU\n",
    "#         local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "#         # zero the parameter gradients\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # forward + backward + optimize\n",
    "#         outputs = model(local_batch)\n",
    "#         loss = criterion(outputs, local_labels.long())\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item()\n",
    "        \n",
    "    \n",
    "    running_loss = running_loss/7500 #Dividing by total number of training examples.\n",
    "    \n",
    "    print('[%d]training loss: %.3f' %       (epoch + 26, running_loss))\n",
    "    \n",
    "    loss_val = 0.0\n",
    "    model.eval()\n",
    "    \n",
    "    for local_batch, local_labels in test_generator:\n",
    "        # Transfer to GPU\n",
    "        local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(local_batch)\n",
    "        loss = criterion(outputs, local_labels.long())\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        loss_val += loss.item()\n",
    "    \n",
    "#     for local_batch, local_labels in test_generator_2:\n",
    "#         # Transfer to GPU\n",
    "#         local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "#         # zero the parameter gradients\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # forward + backward + optimize\n",
    "#         outputs = model(local_batch)\n",
    "#         loss = criterion(outputs, local_labels.long())\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         loss_val += loss.item()\n",
    "\n",
    "    loss_val = loss_val/474\n",
    "    print('[%d]validation loss: %.3f' %       (epoch + 26, loss_val))\n",
    "    \n",
    "    writer.add_scalar('loss/training_loss', running_loss, epoch +55)\n",
    "    writer.add_scalar('loss/validation_loss', loss_val, epoch + 55)\n",
    "    \n",
    "    if (epoch+1)%5 == 0:\n",
    "        torch.save(model.state_dict(), 'runs/'+exp_name+\"/epoch\"+str(epoch+26)+\".pth\")\n",
    "        \n",
    "    #Saving the best model weights\n",
    "    if running_loss < best_val_loss:\n",
    "        best_val_loss = running_loss\n",
    "        torch.save(model.state_dict(), 'runs/'+exp_name+'/best_val_recent.wts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M6IAsgJ9lYX7"
   },
   "outputs": [],
   "source": [
    "# exp_name = 'exp-2_5epochs_lr_0.001_batch_size_8_weights_road_pavement_5_sizeby2'\n",
    "exp_name = 'exp_enet_epoch_30_fullhd'\n",
    "video_name = '2_2_images/'+exp_name+'_more.avi'\n",
    "video = cv.VideoWriter(video_name,cv.VideoWriter_fourcc(*'DIVX'), 8, ( 1280,720))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dEi-Tg7ISpiy"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FnkN6BRxQFIo"
   },
   "outputs": [],
   "source": [
    "for i in range(1,491):\n",
    "  img = \"2_2_images/2_2_gan/\"+str(i)+\".jpg\"\n",
    "  X = transform_train(Image.open(img))\n",
    "  X = torch.unsqueeze(X,0)\n",
    "  y = model(X.to(device))\n",
    "  y = torch.squeeze(y)\n",
    "  a,b = torch.topk(y, 3,dim=0)\n",
    "  b = np.asarray(b.detach().to('cpu'))\n",
    "  blank_image = cv.imread(img)\n",
    "  blank_image[:,:,1] = (255-blank_image[:,:,1])*(1*(b[0]==0)+1*(b[1]==0))+blank_image[:,:,1]\n",
    "  video.write(blank_image.astype(np.uint8))\n",
    "  #cv2_imshow(blank_image)\n",
    "# for i in range(b.shape[1]):\n",
    "#   for j in range(b.shape[2]):\n",
    "#     if int(b[0][i][j])==0 or int(b[1][i][j])==0 :\n",
    "#       blank_image[i][j][1] = 255\n",
    "video.release() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 737
    },
    "colab_type": "code",
    "id": "uHV0TfpVyEVH",
    "outputId": "e4da2f8a-417f-4b8b-ded4-52d2235569aa"
   },
   "outputs": [],
   "source": [
    "# cv2_imshow(blank_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3phQ9g5SBuxa",
    "outputId": "7c03b4fb-7294-44e1-bed7-eb848d786007"
   },
   "outputs": [],
   "source": [
    "\n",
    "# blank_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PV4H9U_QCNa1"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q3VuRzgiU0Ff"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NBQwQOV8CRr7"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SEnlOcR0CaxY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TzwawkI5CcKY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9q1i1gffEe4t"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 737
    },
    "colab_type": "code",
    "id": "M8zq2W3WEnQI",
    "outputId": "8cef6241-0006-4f0c-c56d-d92a8d0b29d8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RyRBieIaNKVh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "gohkmqbWsIMX",
    "outputId": "5bb29d8f-d68e-44a7-e035-32a5cc103813"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1, 3, 720, 1280))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(3, 8, (5,5), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = nn.Conv2d(8, 8, (5,5), (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = conv1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = conv2(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxp1 = nn.MaxPool2d(kernel_size=(3,3), stride=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = maxp1(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1, 3, 720, 1280))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(3, 8, (3,3), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxp1 = nn.MaxPool2d(kernel_size=(2,2), stride=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = conv1(x)\n",
    "y1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = maxp1(y1)\n",
    "y2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = nn.Conv2d(8, 8, (5,5), (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y3 = conv2(y2)\n",
    "y3.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxp2 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y4 = maxp2(y3)\n",
    "y4.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1, 3, 720, 1280))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_branch = nn.MaxPool2d(3, stride=2, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ext_branch(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(3, 8, (3,3), 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = conv1(x)\n",
    "y1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxp1 = nn.MaxPool2d(kernel_size=(2,2), stride=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = maxp1(y1)\n",
    "y2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = nn.Conv2d(8, 8, (5,5), (1,1), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y3 = conv2(y2)\n",
    "y3.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxp2 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2), padding=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y4 = maxp2(y3)\n",
    "y4.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "IDD_Enet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
